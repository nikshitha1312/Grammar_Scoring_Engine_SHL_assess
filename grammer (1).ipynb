{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1f8603-fb69-48f4-925f-351a40b4f405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\niksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\niksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From C:\\Users\\niksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\niksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From C:\\Users\\niksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\niksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From C:\\Users\\niksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\niksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From C:\\Users\\niksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 74ms/step - loss: 13.0161 - mae: 3.4205 - val_loss: 9.7590 - val_mae: 2.9009 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 7.7257 - mae: 2.5265 - val_loss: 5.8356 - val_mae: 2.1366 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.4224 - mae: 1.7988 - val_loss: 3.5366 - val_mae: 1.5725 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.7424 - mae: 1.3638 - val_loss: 2.3568 - val_mae: 1.2446 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.0001 - mae: 1.1658 - val_loss: 1.8975 - val_mae: 1.1029 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.7104 - mae: 1.0832 - val_loss: 1.7507 - val_mae: 1.0510 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.5496 - mae: 1.0299 - val_loss: 1.6929 - val_mae: 1.0332 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.4002 - mae: 0.9771 - val_loss: 1.6323 - val_mae: 1.0202 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2810 - mae: 0.9324 - val_loss: 1.5740 - val_mae: 1.0103 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1875 - mae: 0.8969 - val_loss: 1.5399 - val_mae: 1.0057 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0934 - mae: 0.8589 - val_loss: 1.5024 - val_mae: 0.9982 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0270 - mae: 0.8310 - val_loss: 1.4766 - val_mae: 0.9965 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9583 - mae: 0.8006 - val_loss: 1.4428 - val_mae: 0.9883 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9004 - mae: 0.7727 - val_loss: 1.4326 - val_mae: 0.9893 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8452 - mae: 0.7480 - val_loss: 1.4092 - val_mae: 0.9831 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8004 - mae: 0.7256 - val_loss: 1.3915 - val_mae: 0.9772 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7493 - mae: 0.6979 - val_loss: 1.3663 - val_mae: 0.9713 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7132 - mae: 0.6769 - val_loss: 1.3540 - val_mae: 0.9665 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6744 - mae: 0.6574 - val_loss: 1.3452 - val_mae: 0.9639 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6458 - mae: 0.6436 - val_loss: 1.3337 - val_mae: 0.9570 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6103 - mae: 0.6228 - val_loss: 1.3160 - val_mae: 0.9496 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5850 - mae: 0.6077 - val_loss: 1.3086 - val_mae: 0.9458 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5541 - mae: 0.5904 - val_loss: 1.2893 - val_mae: 0.9407 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5293 - mae: 0.5760 - val_loss: 1.2775 - val_mae: 0.9366 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5032 - mae: 0.5610 - val_loss: 1.2751 - val_mae: 0.9364 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4858 - mae: 0.5533 - val_loss: 1.2734 - val_mae: 0.9343 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4628 - mae: 0.5392 - val_loss: 1.2494 - val_mae: 0.9253 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4431 - mae: 0.5251 - val_loss: 1.2405 - val_mae: 0.9208 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4234 - mae: 0.5148 - val_loss: 1.2471 - val_mae: 0.9249 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4060 - mae: 0.5049 - val_loss: 1.2373 - val_mae: 0.9197 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3913 - mae: 0.4960 - val_loss: 1.2221 - val_mae: 0.9119 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3737 - mae: 0.4846 - val_loss: 1.2087 - val_mae: 0.9094 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3583 - mae: 0.4742 - val_loss: 1.2049 - val_mae: 0.9082 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3448 - mae: 0.4650 - val_loss: 1.2062 - val_mae: 0.9096 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3319 - mae: 0.4563 - val_loss: 1.1939 - val_mae: 0.9012 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3182 - mae: 0.4462 - val_loss: 1.1951 - val_mae: 0.9010 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3065 - mae: 0.4386 - val_loss: 1.1746 - val_mae: 0.8928 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2957 - mae: 0.4295 - val_loss: 1.1816 - val_mae: 0.8938 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2833 - mae: 0.4203 - val_loss: 1.1699 - val_mae: 0.8928 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2729 - mae: 0.4124 - val_loss: 1.1596 - val_mae: 0.8869 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2625 - mae: 0.4048 - val_loss: 1.1685 - val_mae: 0.8876 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2525 - mae: 0.3955 - val_loss: 1.1542 - val_mae: 0.8839 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2433 - mae: 0.3894 - val_loss: 1.1489 - val_mae: 0.8826 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2345 - mae: 0.3821 - val_loss: 1.1593 - val_mae: 0.8865 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2251 - mae: 0.3724 - val_loss: 1.1453 - val_mae: 0.8755 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2162 - mae: 0.3645 - val_loss: 1.1479 - val_mae: 0.8785 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2089 - mae: 0.3581 - val_loss: 1.1411 - val_mae: 0.8747 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2018 - mae: 0.3513 - val_loss: 1.1367 - val_mae: 0.8753 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1949 - mae: 0.3449 - val_loss: 1.1323 - val_mae: 0.8701 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1867 - mae: 0.3359 - val_loss: 1.1260 - val_mae: 0.8677 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1802 - mae: 0.3297 - val_loss: 1.1332 - val_mae: 0.8697 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1727 - mae: 0.3225 - val_loss: 1.1293 - val_mae: 0.8691 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1687 - mae: 0.3189 - val_loss: 1.1252 - val_mae: 0.8649 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1607 - mae: 0.3103 - val_loss: 1.1110 - val_mae: 0.8577 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1541 - mae: 0.3032 - val_loss: 1.1236 - val_mae: 0.8625 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1498 - mae: 0.2978 - val_loss: 1.1119 - val_mae: 0.8564 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1445 - mae: 0.2925 - val_loss: 1.1242 - val_mae: 0.8619 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1400 - mae: 0.2871 - val_loss: 1.1130 - val_mae: 0.8562 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1333 - mae: 0.2801 - val_loss: 1.1009 - val_mae: 0.8495 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1286 - mae: 0.2750 - val_loss: 1.1040 - val_mae: 0.8498 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1241 - mae: 0.2695 - val_loss: 1.1084 - val_mae: 0.8515 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1223 - mae: 0.2684 - val_loss: 1.0962 - val_mae: 0.8452 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1151 - mae: 0.2602 - val_loss: 1.1022 - val_mae: 0.8476 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1144 - mae: 0.2561 - val_loss: 1.0987 - val_mae: 0.8431 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1105 - mae: 0.2532 - val_loss: 1.0859 - val_mae: 0.8386 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1042 - mae: 0.2455 - val_loss: 1.1003 - val_mae: 0.8482 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0997 - mae: 0.2399 - val_loss: 1.0873 - val_mae: 0.8377 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0971 - mae: 0.2353 - val_loss: 1.0900 - val_mae: 0.8377 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0943 - mae: 0.2327 - val_loss: 1.0928 - val_mae: 0.8421 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0923 - mae: 0.2293 - val_loss: 1.0793 - val_mae: 0.8316 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0868 - mae: 0.2220 - val_loss: 1.0848 - val_mae: 0.8372 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0838 - mae: 0.2159 - val_loss: 1.0767 - val_mae: 0.8290 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0795 - mae: 0.2128 - val_loss: 1.0824 - val_mae: 0.8316 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0777 - mae: 0.2091 - val_loss: 1.0804 - val_mae: 0.8290 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0737 - mae: 0.2038 - val_loss: 1.0814 - val_mae: 0.8273 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0727 - mae: 0.2013 - val_loss: 1.0779 - val_mae: 0.8288 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0698 - mae: 0.1971 - val_loss: 1.0755 - val_mae: 0.8242 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0655 - mae: 0.1895 - val_loss: 1.0785 - val_mae: 0.8268 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0657 - mae: 0.1909 - val_loss: 1.0681 - val_mae: 0.8204 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0618 - mae: 0.1851 - val_loss: 1.0716 - val_mae: 0.8192 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0591 - mae: 0.1805 - val_loss: 1.0750 - val_mae: 0.8254 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0577 - mae: 0.1774 - val_loss: 1.0659 - val_mae: 0.8174 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0549 - mae: 0.1728 - val_loss: 1.0659 - val_mae: 0.8167 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0531 - mae: 0.1698 - val_loss: 1.0663 - val_mae: 0.8156 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0507 - mae: 0.1662 - val_loss: 1.0613 - val_mae: 0.8165 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0498 - mae: 0.1645 - val_loss: 1.0635 - val_mae: 0.8131 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0469 - mae: 0.1592 - val_loss: 1.0729 - val_mae: 0.8196 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0452 - mae: 0.1544 - val_loss: 1.0545 - val_mae: 0.8103 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0437 - mae: 0.1527 - val_loss: 1.0629 - val_mae: 0.8138 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0415 - mae: 0.1489 - val_loss: 1.0642 - val_mae: 0.8148 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0398 - mae: 0.1444 - val_loss: 1.0661 - val_mae: 0.8152 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0385 - mae: 0.1420 - val_loss: 1.0590 - val_mae: 0.8123 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0365 - mae: 0.1387 - val_loss: 1.0661 - val_mae: 0.8138 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0350 - mae: 0.1354 - val_loss: 1.0662 - val_mae: 0.8140 - lr: 2.0000e-04\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0345 - mae: 0.1343 - val_loss: 1.0635 - val_mae: 0.8128 - lr: 2.0000e-04\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0343 - mae: 0.1335 - val_loss: 1.0586 - val_mae: 0.8104 - lr: 2.0000e-04\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0340 - mae: 0.1327 - val_loss: 1.0618 - val_mae: 0.8118 - lr: 2.0000e-04\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0336 - mae: 0.1320 - val_loss: 1.0634 - val_mae: 0.8125 - lr: 2.0000e-04\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "MAE: 0.93\n",
      "R²: -0.02\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from transformers import pipeline\n",
    "import language_tool_python\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Load and preprocess dataset\n",
    "train_df = pd.read_csv(r'C:\\Users\\niksh\\Downloads\\archive (1)\\dataset\\train.csv')\n",
    "train_df['file_path'] = train_df['filename'].apply(\n",
    "    lambda x: os.path.join(r\"C:\\Users\\niksh\\Downloads\\archive (1)\\dataset\\audios_train\", x)\n",
    ")\n",
    "train_df.rename(columns={'label': 'grammar_score'}, inplace=True)\n",
    "\n",
    "# Audio feature extraction\n",
    "def extract_audio_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=16000)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    return np.hstack([\n",
    "        np.mean(mfcc, axis=1),\n",
    "        np.mean(chroma, axis=1),\n",
    "        np.mean(contrast, axis=1)\n",
    "    ])\n",
    "\n",
    "# Transcription pipeline\n",
    "asr_pipe = pipeline(\"automatic-speech-recognition\",\n",
    "                    model=\"openai/whisper-medium\",\n",
    "                    device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "    return asr_pipe(file_path)[\"text\"]\n",
    "\n",
    "# Connect to local LanguageTool server\n",
    "tool = language_tool_python.LanguageTool('en-US', remote_server='http://localhost:8081')\n",
    "\n",
    "# Grammar feature extraction\n",
    "def grammar_features(text):\n",
    "    matches = tool.check(text)\n",
    "    return [\n",
    "        len(matches),                         # Total grammar issues\n",
    "        len(set(m.ruleId for m in matches)),  # Unique grammar rules triggered\n",
    "        len(text),                            # Length of text\n",
    "        len(text.split())                     # Number of words\n",
    "    ]\n",
    "\n",
    "# Extract and combine features\n",
    "audio_features_list, text_features_list, labels = [], [], []\n",
    "\n",
    "for _, row in train_df.iterrows():\n",
    "    try:\n",
    "        path = row['file_path']\n",
    "        score = row['grammar_score']\n",
    "\n",
    "        audio_feat = extract_audio_features(path)\n",
    "        transcript = transcribe_audio(path)\n",
    "        grammar_feat = grammar_features(transcript)\n",
    "\n",
    "        audio_features_list.append(audio_feat)\n",
    "        text_features_list.append(grammar_feat)\n",
    "        labels.append(score)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {row['filename']} due to error: {e}\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_audio = np.array(audio_features_list)\n",
    "X_text = np.array(text_features_list)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Normalize features\n",
    "scaler_audio = StandardScaler()\n",
    "scaler_text = StandardScaler()\n",
    "\n",
    "X_audio = scaler_audio.fit_transform(X_audio)\n",
    "X_text = scaler_text.fit_transform(X_text)\n",
    "\n",
    "# Train-test split\n",
    "X_train_audio, X_test_audio, X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_audio, X_text, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "audio_input = Input(shape=(X_audio.shape[1],))\n",
    "text_input = Input(shape=(X_text.shape[1],))\n",
    "\n",
    "x_audio = Dense(128, activation='relu')(audio_input)\n",
    "x_text = Dense(128, activation='relu')(text_input)\n",
    "\n",
    "merged = Concatenate()([x_audio, x_text])\n",
    "output = Dense(1, activation='linear')(merged)\n",
    "\n",
    "model = Model(inputs=[audio_input, text_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train_audio, X_train_text],\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(factor=0.2, patience=5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict([X_test_audio, X_test_text]).flatten()\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55779e9-e614-45f5-8140-fa36d08bb003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7402b07-192c-48d9-a11a-f168e3fb1fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
